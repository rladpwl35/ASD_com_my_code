{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dig.xgraph.method import SubgraphX\n",
    "from dig.xgraph.method.subgraphx import find_closest_node_result\n",
    "\n",
    "from model import GNN\n",
    "from pretrain_joao import graphcl\n",
    "\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree, softmax\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
    "import torch.nn.functional as F\n",
    "from loader import BioDataset\n",
    "from dataloader import DataLoaderFinetune\n",
    "from torch_scatter import scatter_add\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "class GNN_graphpred_for_x(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Extension of GIN to incorporate edge information by concatenation.\n",
    "\n",
    "    Args:\n",
    "        num_layer (int): the number of GNN layers\n",
    "        emb_dim (int): dimensionality of embeddings\n",
    "        num_tasks (int): number of tasks in multi-task learning scenario\n",
    "        drop_ratio (float): dropout rate\n",
    "        JK (str): last, concat, max or sum.\n",
    "        graph_pooling (str): sum, mean, max, attention, set2set\n",
    "        \n",
    "    See https://arxiv.org/abs/1810.00826\n",
    "    JK-net: https://arxiv.org/abs/1806.03536\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, emb_dim, num_tasks, JK = \"last\", drop_ratio = 0, graph_pooling = \"mean\", gnn_type = \"graphsage\"):\n",
    "        super(GNN_graphpred_for_x, self).__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        #if self.num_layer < 2:\n",
    "        #    raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.gnn = GNN(num_layer, emb_dim, JK, drop_ratio, gnn_type = gnn_type)\n",
    "\n",
    "        #Different kind of graph pooling\n",
    "        if graph_pooling == \"sum\":\n",
    "            self.pool = global_add_pool\n",
    "        elif graph_pooling == \"mean\":\n",
    "            self.pool = global_mean_pool\n",
    "        elif graph_pooling == \"max\":\n",
    "            self.pool = global_max_pool\n",
    "        elif graph_pooling == \"attention\":\n",
    "            self.pool = GlobalAttention(gate_nn = torch.nn.Linear(100, 1))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "        self.linear = torch.nn.Linear(self.emb_dim, 100)\n",
    "        self.graph_pred_linear = torch.nn.Linear(100, self.num_tasks)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    #def from_pretrained(self, model_file):\n",
    "    #    self.gnn.load_state_dict(torch.load(model_file, map_location=lambda storage, loc: storage))\n",
    "\n",
    "    def forward(self, x, edge_index, do_visualize=False):\n",
    "        #x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        node_representation = self.gnn(x, edge_index, None)\n",
    "        device = torch.device('cuda:4')\n",
    "        pooled = self.pool(node_representation, torch.LongTensor([0]*116).to(device))\n",
    "        \n",
    "        #graph_rep = torch.cat([pooled, center_node_rep], dim = 1)\n",
    "        graph_rep = self.linear(pooled)\n",
    "        \n",
    "        #if do_visualize:\n",
    "        #    visualize(graph_rep, data.y)      \n",
    "  \n",
    "        return self.softmax(self.graph_pred_linear(graph_rep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layer = 2\n",
    "emb_dim = 128\n",
    "num_tasks = 2\n",
    "dropout_ratio = 0.5\n",
    "graph_pooling = 'mean'\n",
    "gnn_type = 'graphsage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN_graphpred_for_x(num_layer, emb_dim, num_tasks, JK = \"last\", drop_ratio=dropout_ratio, graph_pooling=graph_pooling, gnn_type = gnn_type)\n",
    "model_graphcl = graphcl(model.gnn, emb_dim)\n",
    "model.gnn = model_graphcl.gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/nasdata3/kyj/graphcl/GraphCL_Automated/transferLearning_MoleculeNet_PPI/bio/fintune_weight/'\n",
    "FILE = 'graphsage_none_lr1e-4_NYU_epoch300_batch800_s_decay0_layer2_5fold_dim128_fc100_fold5_seed0.pt'\n",
    "model.load_state_dict(torch.load(PATH+FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN_graphpred_for_x(\n",
      "  (gnn): GNN(\n",
      "    (gnns): ModuleList(\n",
      "      (0): GraphSAGEConv(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (edge_encoder): Linear(in_features=9, out_features=128, bias=True)\n",
      "        (linear1): Linear(in_features=232, out_features=128, bias=True)\n",
      "      )\n",
      "      (1): GraphSAGEConv(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (edge_encoder): Linear(in_features=9, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=128, out_features=100, bias=True)\n",
      "  (graph_pred_linear): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABIDE1에서 제공하는 전처리된 aal roi 사용해서 ASD and control classification(downstream task)을 위한 dataset 만들기\n",
    "sub_list = open('/nasdata4/kyj0305/ABIDE/Download_preprocess/NYU_list','r').read().split('\\n')\n",
    "sub_list.pop()\n",
    "one_hot = torch.zeros(116,116).to(device)\n",
    "for i in range(116):\n",
    "    one_hot[i][i] = 1\n",
    "dataset=[]\n",
    "x = []\n",
    "edge_index = []\n",
    "for i in sub_list:\n",
    "    with open(f'/nasdata4/kyj0305/ABIDE/Download_preprocess/roi_aal_1d/pcc_{i}.txt','r') as f:\n",
    "       #l = pickle.load(f)\n",
    "       x =[[float(num) for num in line.split(' ')] for line in f]\n",
    "       x = torch.FloatTensor(x).to(device)\n",
    "       x = torch.transpose(x,0,1)\n",
    "       x = torch.cat((x,one_hot),1)\n",
    "       #print(x)\n",
    "        \n",
    "    with open(f'/nasdata4/kyj0305/ABIDE/Download_preprocess/y/{i}.txt','r') as f:\n",
    "        f = f.read()\n",
    "        y = torch.LongTensor([int(f)]).to(device)\n",
    "        \n",
    "    with open(f'/nasdata4/kyj0305/ABIDE/Download_preprocess/edge/edge_index20/ROICorrelation_FisherZ_{i}_edge_index.txt') as f:\n",
    "        edge_index = torch.LongTensor([[int(num) for num in line.split()] for line in f]).to(device)\n",
    "        edge_index = torch.transpose(edge_index,0,1)\n",
    "\n",
    "    my_data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "    dataset.append(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000,  0.3842,  0.0923,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.3842,  1.0000,  0.0387,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0923,  0.0387,  1.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.1210,  0.0976, -0.0380,  ...,  1.0000,  0.0000,  0.0000],\n",
      "        [-0.2144,  0.2723,  0.1242,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.2691,  0.1478, -0.0415,  ...,  0.0000,  0.0000,  1.0000]],\n",
      "       device='cuda:4')\n",
      "tensor([[  0,   0,   0,  ..., 113, 113, 113],\n",
      "        [  1,   2,   3,  ...,  99, 102, 110]], device='cuda:4')\n"
     ]
    }
   ],
   "source": [
    "x = dataset[0].x\n",
    "edge_indel=dataset[0].edge_index\n",
    "print(x)\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/nasdata3/kyj/graphcl/GraphCL_Automated/transferLearning_MoleculeNet_PPI/bio/subgraphx.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B210.117.210.27/nasdata3/kyj/graphcl/GraphCL_Automated/transferLearning_MoleculeNet_PPI/bio/subgraphx.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m explainer \u001b[39m=\u001b[39m SubgraphX(model, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B210.117.210.27/nasdata3/kyj/graphcl/GraphCL_Automated/transferLearning_MoleculeNet_PPI/bio/subgraphx.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m _, explanation_results, related_preds \u001b[39m=\u001b[39m explainer(x,edge_index, max_nodes\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/subgraphx.py:852\u001b[0m, in \u001b[0;36mSubgraphX.__call__\u001b[0;34m(self, x, edge_index, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         saved_results \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    851\u001b[0m \u001b[39mfor\u001b[39;00m label_idx, label \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(ex_labels):\n\u001b[0;32m--> 852\u001b[0m     results, related_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplain(x, edge_index,\n\u001b[1;32m    853\u001b[0m                                          label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m    854\u001b[0m                                          max_nodes\u001b[39m=\u001b[39;49mmax_nodes,\n\u001b[1;32m    855\u001b[0m                                          node_idx\u001b[39m=\u001b[39;49mnode_idx,\n\u001b[1;32m    856\u001b[0m                                          saved_MCTSInfo_list\u001b[39m=\u001b[39;49msaved_results)\n\u001b[1;32m    857\u001b[0m     related_preds\u001b[39m.\u001b[39mappend(related_pred)\n\u001b[1;32m    858\u001b[0m     explanation_results\u001b[39m.\u001b[39mappend(results)\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/subgraphx.py:766\u001b[0m, in \u001b[0;36mSubgraphX.explain\u001b[0;34m(self, x, edge_index, label, max_nodes, node_idx, saved_MCTSInfo_list)\u001b[0m\n\u001b[1;32m    764\u001b[0m     payoff_func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_reward_func(value_func)\n\u001b[1;32m    765\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmcts_state_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mcts_class(x, edge_index, score_func\u001b[39m=\u001b[39mpayoff_func)\n\u001b[0;32m--> 766\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmcts_state_map\u001b[39m.\u001b[39;49mmcts(verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose)\n\u001b[1;32m    768\u001b[0m \u001b[39m# l sharply score\u001b[39;00m\n\u001b[1;32m    769\u001b[0m value_func \u001b[39m=\u001b[39m GnnNetsGC2valueFunc(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, target_class\u001b[39m=\u001b[39mlabel)\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/subgraphx.py:585\u001b[0m, in \u001b[0;36mMCTS.mcts\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe nodes in graph is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mnumber_of_nodes()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    584\u001b[0m \u001b[39mfor\u001b[39;00m rollout_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_rollout):\n\u001b[0;32m--> 585\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmcts_rollout(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[1;32m    586\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m    587\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAt the \u001b[39m\u001b[39m{\u001b[39;00mrollout_idx\u001b[39m}\u001b[39;00m\u001b[39m rollout, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_map)\u001b[39m}\u001b[39;00m\u001b[39m states that have been explored.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/subgraphx.py:570\u001b[0m, in \u001b[0;36mMCTS.mcts_rollout\u001b[0;34m(self, tree_node)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m find_same_child:\n\u001b[1;32m    568\u001b[0m         tree_node\u001b[39m.\u001b[39mchildren\u001b[39m.\u001b[39mappend(new_node)\n\u001b[0;32m--> 570\u001b[0m scores \u001b[39m=\u001b[39m compute_scores(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_func, tree_node\u001b[39m.\u001b[39;49mchildren)\n\u001b[1;32m    571\u001b[0m \u001b[39mfor\u001b[39;00m child, score \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(tree_node\u001b[39m.\u001b[39mchildren, scores):\n\u001b[1;32m    572\u001b[0m     child\u001b[39m.\u001b[39mP \u001b[39m=\u001b[39m score\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/subgraphx.py:164\u001b[0m, in \u001b[0;36mcompute_scores\u001b[0;34m(score_func, children)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mfor\u001b[39;00m child \u001b[39min\u001b[39;00m children:\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m child\u001b[39m.\u001b[39mP \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m         score \u001b[39m=\u001b[39m score_func(child\u001b[39m.\u001b[39;49mcoalition, child\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    165\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m         score \u001b[39m=\u001b[39m child\u001b[39m.\u001b[39mP\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/shapley.py:218\u001b[0m, in \u001b[0;36mmc_l_shapley\u001b[0;34m(coalition, data, local_radius, value_func, subgraph_building_method, sample_num)\u001b[0m\n\u001b[1;32m    215\u001b[0m exclude_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(set_exclude_masks, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    216\u001b[0m include_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(set_include_masks, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    217\u001b[0m marginal_contributions \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 218\u001b[0m     marginal_contribution(data, exclude_mask, include_mask, value_func, subgraph_build_func)\n\u001b[1;32m    220\u001b[0m mc_l_shapley_value \u001b[39m=\u001b[39m (marginal_contributions)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    221\u001b[0m \u001b[39mreturn\u001b[39;00m mc_l_shapley_value\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/shapley.py:75\u001b[0m, in \u001b[0;36mmarginal_contribution\u001b[0;34m(data, exclude_mask, include_mask, value_func, subgraph_build_func)\u001b[0m\n\u001b[1;32m     72\u001b[0m marginal_contribution_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m exclude_data, include_data \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m---> 75\u001b[0m     exclude_values \u001b[39m=\u001b[39m value_func(exclude_data)\n\u001b[1;32m     76\u001b[0m     include_values \u001b[39m=\u001b[39m value_func(include_data)\n\u001b[1;32m     77\u001b[0m     margin_values \u001b[39m=\u001b[39m include_values \u001b[39m-\u001b[39m exclude_values\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/dig/xgraph/method/shapley.py:14\u001b[0m, in \u001b[0;36mGnnNetsGC2valueFunc.<locals>.value_func\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalue_func\u001b[39m(batch):\n\u001b[1;32m     13\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 14\u001b[0m         logits \u001b[39m=\u001b[39m gnnNets(data\u001b[39m=\u001b[39;49mbatch)\n\u001b[1;32m     15\u001b[0m         probs \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m         score \u001b[39m=\u001b[39m probs[:, target_class]\n",
      "File \u001b[0;32m/nasdata3/kyj/anaconda3/envs/graphcl/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1052\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'data'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "explainer = SubgraphX(model, num_classes=2, device=4)\n",
    "_, explanation_results, related_preds = explainer(x, edge_index, max_nodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('graphcl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23ac561d2360d1d12670ea2b424acbe872731016351d06d028ee8d8e30943325"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
